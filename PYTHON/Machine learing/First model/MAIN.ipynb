{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab44e61",
   "metadata": {},
   "source": [
    "A machine learning model which helps to predect that the car is in buying condition or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1918595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb975d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0673e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92de6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9f97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36eaf53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('car.data') #Importing data by using pandas lib function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c5ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   buying  maint doors persons lug_boot safety  class\n",
      "0   vhigh  vhigh     2       2    small    low  unacc\n",
      "1   vhigh  vhigh     2       2    small    med  unacc\n",
      "2   vhigh  vhigh     2       2    small   high  unacc\n",
      "3   vhigh  vhigh     2       2      med    low  unacc\n",
      "4   vhigh  vhigh     2       2      med    med  unacc\n",
      "5   vhigh  vhigh     2       2      med   high  unacc\n",
      "6   vhigh  vhigh     2       2      big    low  unacc\n",
      "7   vhigh  vhigh     2       2      big    med  unacc\n",
      "8   vhigh  vhigh     2       2      big   high  unacc\n",
      "9   vhigh  vhigh     2       4    small    low  unacc\n",
      "10  vhigh  vhigh     2       4    small    med  unacc\n",
      "11  vhigh  vhigh     2       4    small   high  unacc\n",
      "12  vhigh  vhigh     2       4      med    low  unacc\n",
      "13  vhigh  vhigh     2       4      med    med  unacc\n",
      "14  vhigh  vhigh     2       4      med   high  unacc\n",
      "15  vhigh  vhigh     2       4      big    low  unacc\n",
      "16  vhigh  vhigh     2       4      big    med  unacc\n",
      "17  vhigh  vhigh     2       4      big   high  unacc\n",
      "18  vhigh  vhigh     2    more    small    low  unacc\n",
      "19  vhigh  vhigh     2    more    small    med  unacc\n"
     ]
    }
   ],
   "source": [
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8498dad",
   "metadata": {},
   "source": [
    "In this model we are going to use \"buying\", \"maint\", \"safety\" as a Label. Here 'X' represents label as a [\"buying\", \"maint\", \"safety\"]  and 'Y' represent lable as a \"class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a670259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    'buying',\n",
    "    'maint',\n",
    "    'safety'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66a54872",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cba8286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['buying', 'maint', 'safety']]       class\n",
      "0     unacc\n",
      "1     unacc\n",
      "2     unacc\n",
      "3     unacc\n",
      "4     unacc\n",
      "...     ...\n",
      "1723   good\n",
      "1724  vgood\n",
      "1725  unacc\n",
      "1726   good\n",
      "1727  vgood\n",
      "\n",
      "[1728 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a3829",
   "metadata": {},
   "source": [
    "Converting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce08cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0']\n",
      " ['1']\n",
      " ['2']]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# Convert the list to a numpy array for easier indexing\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "\n",
    "for i in range(len(x[0])):\n",
    "    x[:, 0] = le.fit_transform(x[:, 0])\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1111de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0']\n",
      " ['1']\n",
      " ['2']]       class\n",
      "0     unacc\n",
      "1     unacc\n",
      "2     unacc\n",
      "3     unacc\n",
      "4     unacc\n",
      "...     ...\n",
      "1723   good\n",
      "1724  vgood\n",
      "1725  unacc\n",
      "1726   good\n",
      "1727  vgood\n",
      "\n",
      "[1728 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ea60cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [-1]\n",
      " [-1]\n",
      " ...\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'unacc': 0,\n",
    "    'acc': 1,\n",
    "    'good': 2,\n",
    "    'vgood': 3\n",
    "}\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "# Map the values using label_mapping dictionary and provide a default value of -1\n",
    "mapped_values = np.array([label_mapping.get(value, -1) for value in y[:, 0]])\n",
    "\n",
    "# Update the first column of the array with the mapped values\n",
    "y[:, 0] = mapped_values\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0f616",
   "metadata": {},
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3ab0004",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3, 1728]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m knn \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mKNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m      4\u001b[0m prediction \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3, 1728]"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=25, weights='uniform')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "knn.fit(x_train, y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"predictions:\", prediction)\n",
    "print(\"accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38548070",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5184, 1728]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mapped_values)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m knn \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mKNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     36\u001b[0m prediction \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5184, 1728]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv('car.data')\n",
    "\n",
    "x = np.array([\n",
    "    'buying',\n",
    "    'maint',\n",
    "    'safety'\n",
    "])\n",
    "\n",
    "y = np.array(data['class'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "x = np.repeat(x, len(y)).reshape(-1, 1)\n",
    "\n",
    "for i in range(len(x[0])):\n",
    "    x[:, 0] = le.fit_transform(x[:, 0])\n",
    "\n",
    "label_mapping = {\n",
    "    'unacc': 0,\n",
    "    'acc': 1,\n",
    "    'good': 2,\n",
    "    'vgood': 3\n",
    "}\n",
    "\n",
    "mapped_values = np.array([label_mapping.get(value, -1) for value in y])\n",
    "y = np.array(mapped_values).reshape(-1, 1)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=25, weights='uniform')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "knn.fit(x_train, y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"predictions:\", prediction)\n",
    "print(\"accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8be010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
